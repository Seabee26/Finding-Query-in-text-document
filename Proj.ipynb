{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=[line.rstrip() for line in open('001.txt')]\n",
    "d=''.join(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (2,10):\n",
    "    msg=[line.rstrip() for line in open('00'+str(i)+'.txt')]\n",
    "    c=c+1\n",
    "    msg=''.join(msg)\n",
    "    df.append(msg)\n",
    "    #d=d+msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10,100):\n",
    "    msg=[line.rstrip() for line in open('0'+str(i)+'.txt')]\n",
    "    c=c+1\n",
    "    msg=''.join(msg)\n",
    "    df.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (100,511):\n",
    "    msg=[line.rstrip() for line in open(str(i)+'.txt')]\n",
    "    c=c+1\n",
    "    msg=''.join(msg)\n",
    "    df.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(msg):\n",
    "    nopunc = [char for char in msg if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame (df,columns=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [Ad, sales, boost, Time, Warner, profitQuarter...\n",
       "1      [Dollar, gains, Greenspan, speechThe, dollar, ...\n",
       "2      [Yukos, unit, buyer, faces, loan, claimThe, ow...\n",
       "3      [High, fuel, prices, hit, BAs, profitsBritish,...\n",
       "4      [Pernod, takeover, talk, lifts, DomecqShares, ...\n",
       "                             ...                        \n",
       "505    [Trial, begins, Spains, top, bankerThe, trial,...\n",
       "506    [UK, economy, ends, year, spurtThe, UK, econom...\n",
       "507    [HealthSouth, exboss, goes, trialThe, former, ...\n",
       "508    [Euro, firms, miss, optimismMore, 90, large, c...\n",
       "509    [Lacroix, label, bought, US, firmLuxury, goods...\n",
       "Name: Text, Length: 510, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>S Korea spending boost to economySouth Korea w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text\n",
       "count                                                 510\n",
       "unique                                                503\n",
       "top     S Korea spending boost to economySouth Korea w...\n",
       "freq                                                    2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['109bn',\n",
       " '111bn',\n",
       " '113bn',\n",
       " '2',\n",
       " '2000',\n",
       " '2003',\n",
       " '2005',\n",
       " '27',\n",
       " '284m',\n",
       " '300m',\n",
       " '336bn',\n",
       " '4209bn',\n",
       " '464000',\n",
       " '5',\n",
       " '500m',\n",
       " '639m',\n",
       " '64',\n",
       " '76',\n",
       " '8',\n",
       " 'AOL',\n",
       " 'AOLTime',\n",
       " 'AOLs',\n",
       " 'Ad',\n",
       " 'Alexander',\n",
       " 'Bertelsmanns',\n",
       " 'Bros',\n",
       " 'Catwoman',\n",
       " 'Commission',\n",
       " 'December',\n",
       " 'Europe',\n",
       " 'Exchange',\n",
       " 'Friday',\n",
       " 'German',\n",
       " 'Google',\n",
       " 'However',\n",
       " 'Lord',\n",
       " 'Parsons',\n",
       " 'Richard',\n",
       " 'Rings',\n",
       " 'SEC',\n",
       " 'Securities',\n",
       " 'Time',\n",
       " 'TimeWarner',\n",
       " 'US',\n",
       " 'Warner',\n",
       " 'Warners',\n",
       " 'accounts',\n",
       " 'adjust',\n",
       " 'advert',\n",
       " 'advertising',\n",
       " 'already',\n",
       " 'also',\n",
       " 'amount',\n",
       " 'analysts',\n",
       " 'around',\n",
       " 'aside',\n",
       " 'back',\n",
       " 'benefited',\n",
       " 'better',\n",
       " 'biggest',\n",
       " 'book',\n",
       " 'boost',\n",
       " 'boosted',\n",
       " 'boxoffice',\n",
       " 'broadband',\n",
       " 'buoyed',\n",
       " 'business',\n",
       " 'chairman',\n",
       " 'charges',\n",
       " 'chief',\n",
       " 'close',\n",
       " 'company',\n",
       " 'concludingTime',\n",
       " 'connections',\n",
       " 'contrast',\n",
       " 'customers',\n",
       " 'deal',\n",
       " 'dip',\n",
       " 'division',\n",
       " 'earnings',\n",
       " 'efforts',\n",
       " 'enhancing',\n",
       " 'estimate',\n",
       " 'exceeding',\n",
       " 'exceptional',\n",
       " 'executive',\n",
       " 'existing',\n",
       " 'expectations',\n",
       " 'expects',\n",
       " 'film',\n",
       " 'final',\n",
       " 'financial',\n",
       " 'firm',\n",
       " 'flexibility',\n",
       " 'flops',\n",
       " 'following',\n",
       " 'fortunes',\n",
       " 'fourth',\n",
       " 'free',\n",
       " 'fullyear',\n",
       " 'gains',\n",
       " 'giant',\n",
       " 'greatly',\n",
       " 'grew',\n",
       " 'growth',\n",
       " 'helped',\n",
       " 'higher',\n",
       " 'highspeed',\n",
       " 'hopes',\n",
       " 'increase',\n",
       " 'inquiry',\n",
       " 'intends',\n",
       " 'internet',\n",
       " 'investors',\n",
       " 'items',\n",
       " 'jumped',\n",
       " 'legal',\n",
       " 'less',\n",
       " 'loss',\n",
       " 'lost',\n",
       " 'lower',\n",
       " 'marginsTimeWarner',\n",
       " 'market',\n",
       " 'media',\n",
       " 'meeting',\n",
       " 'mixed',\n",
       " 'months',\n",
       " 'music',\n",
       " 'needed',\n",
       " 'objectives',\n",
       " 'offered',\n",
       " 'offering',\n",
       " 'offset',\n",
       " 'one',\n",
       " 'oneoff',\n",
       " 'online',\n",
       " 'operating',\n",
       " 'owns',\n",
       " 'part',\n",
       " 'pay',\n",
       " 'performance',\n",
       " 'posted',\n",
       " 'preceding',\n",
       " 'previously',\n",
       " 'probe',\n",
       " 'profit',\n",
       " 'profitQuarterly',\n",
       " 'profits',\n",
       " 'projecting',\n",
       " 'publisher',\n",
       " 'purchase',\n",
       " 'quarter',\n",
       " 'quarters',\n",
       " 'regulators',\n",
       " 'reported',\n",
       " 'reserves',\n",
       " 'resolve',\n",
       " 'restate',\n",
       " 'results',\n",
       " 'revenue',\n",
       " 'revenues',\n",
       " 'review',\n",
       " 'rose',\n",
       " 'said',\n",
       " 'sale',\n",
       " 'sales',\n",
       " 'saw',\n",
       " 'searchengine',\n",
       " 'service',\n",
       " 'set',\n",
       " 'settle',\n",
       " 'sharp',\n",
       " 'sign',\n",
       " 'slightly',\n",
       " 'slump',\n",
       " 'stake',\n",
       " 'strong',\n",
       " 'stronger',\n",
       " 'subscribers',\n",
       " 'third',\n",
       " 'three',\n",
       " 'trilogy',\n",
       " 'try',\n",
       " 'unable',\n",
       " 'underlying',\n",
       " 'users',\n",
       " 'value',\n",
       " 'way',\n",
       " 'wider',\n",
       " 'yearearlier',\n",
       " 'yearearlierThe',\n",
       " 'Â£600m']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='boost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text files are1\n",
      "The text files are2\n",
      "The text files are7\n",
      "The text files are13\n",
      "The text files are31\n",
      "The text files are32\n",
      "The text files are35\n",
      "The text files are44\n",
      "The text files are50\n",
      "The text files are54\n",
      "The text files are56\n",
      "The text files are65\n",
      "The text files are68\n",
      "The text files are75\n",
      "The text files are89\n",
      "The text files are97\n",
      "The text files are106\n",
      "The text files are112\n",
      "The text files are117\n",
      "The text files are120\n",
      "The text files are129\n",
      "The text files are133\n",
      "The text files are134\n",
      "The text files are140\n",
      "The text files are142\n",
      "The text files are150\n",
      "The text files are154\n",
      "The text files are155\n",
      "The text files are159\n",
      "The text files are162\n",
      "The text files are171\n",
      "The text files are180\n",
      "The text files are188\n",
      "The text files are191\n",
      "The text files are199\n",
      "The text files are202\n",
      "The text files are208\n",
      "The text files are210\n",
      "The text files are225\n",
      "The text files are241\n",
      "The text files are247\n",
      "The text files are249\n",
      "The text files are251\n",
      "The text files are253\n",
      "The text files are258\n",
      "The text files are259\n",
      "The text files are270\n",
      "The text files are280\n",
      "The text files are288\n",
      "The text files are312\n",
      "The text files are313\n",
      "The text files are328\n",
      "The text files are344\n",
      "The text files are352\n",
      "The text files are356\n",
      "The text files are383\n",
      "The text files are387\n",
      "The text files are395\n",
      "The text files are429\n",
      "The text files are441\n",
      "The text files are454\n",
      "The text files are456\n",
      "The text files are476\n",
      "The text files are478\n",
      "The text files are485\n",
      "The text files are488\n",
      "The text files are508\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,510):\n",
    "    m=df['Text'][i]\n",
    "    transformer = CountVectorizer(analyzer=process).fit([m])\n",
    "    bowmsg = transformer.transform([m])\n",
    "    for j in transformer.get_feature_names():\n",
    "        if j==query:\n",
    "            val=i+1\n",
    "            print('The text files are'+str(val))\n",
    "            break\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
